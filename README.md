# apacke-spark<img src="https://spark.apache.org/images/spark-logo-rev.svg" >

Apache Sparkâ„¢ is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters.

>*Single node machines: are commonly used for tasks that don't require significant parallel processing or for applications where the data and processing can be handled within the resources of a single system*

- Apache Spark is a unified analytics engine for large-scale data processing
- It provides high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs.
- 

## Installing with 'pip'

pip install pyspark

